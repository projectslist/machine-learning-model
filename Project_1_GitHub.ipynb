{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBzEw9zVhDyCCjiWf4Ue6N"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Steps\n",
        "\n",
        "You need to download the data from https://www.kaggle.com/datasets/arun9872/amazon-customer-reviews-for-mobile-phones-in-uk\n",
        "\n",
        "You may also find some other similar data to use the same logic and practice more\n",
        "\n",
        "1 - Download the data and put it in your local or google drive\n",
        "2 - Run the model on google colab or jupiter on your local"
      ],
      "metadata": {
        "id": "LEAdL6tiWjOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer, StandardScaler, MaxAbsScaler, Normalizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import string\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Read in the CSV file\n",
        "df = pd.read_csv(\"/content/drive/My Drive/ML Lessons/Amazon_Unlocked_Mobile.csv\")\n",
        "df.drop(labels=[\"Product Name\", \"Brand Name\", \"Price\"], axis=1, inplace=True)\n",
        "\n",
        "# Remove rows with missing data\n",
        "df.dropna(subset=[\"Reviews\"], inplace=True)\n",
        "\n",
        "# Visualize the distribution of ratings\n",
        "sns.histplot(df[\"Rating\"], bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5], stat=\"probability\")\n",
        "plt.show()\n",
        "\n",
        "# Define a function to preprocess the text\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        # Convert to lowercase and remove punctuation\n",
        "        text = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    return text\n",
        "\n",
        "# Apply the clean_text function to the \"Reviews\" column\n",
        "df[\"Reviews\"] = df[\"Reviews\"].apply(clean_text)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[\"Reviews\"], df[\"Rating\"], test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a pipeline to preprocess the text and fit a Naive Bayes classifier\n",
        "# you can try different vectorizer\n",
        "# Different vectorizer or classifier change the prediction score \n",
        "pipeline = Pipeline([\n",
        "    (\"clean_text\", FunctionTransformer(clean_text)),\n",
        "    (\"vectorizer\", CountVectorizer()), # Prediction accuracy: 0.7172531296824399\n",
        "    #(\"vectorizer\", TfidfVectorizer()), # Prediction accuracy: 0.7085528541737155\n",
        "    (\"scaler\", StandardScaler(with_mean=False)),\n",
        "    (\"maxabs\", MaxAbsScaler()),\n",
        "    (\"normalize\", Normalizer()),\n",
        "    (\"poly\", PolynomialFeatures(degree=1)),\n",
        "    #(\"classifier\", MultinomialNB()), # # Prediction accuracy: 0.7172531296824399\n",
        "    #(\"classifier\", LogisticRegression()), # Prediction accuracy: 0.7880878727826381\n",
        "    #(\"classifier\", DecisionTreeClassifier(random_state=42)), #Prediction accuracy: 0.8754289719174441\n",
        "    (\"classifier\", RandomForestClassifier(n_estimators=100, random_state=42)), #Prediction accuracy: 0.8950529266760114\n",
        "\n",
        "    \n",
        "    \n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Convert the \"Rating\" column to labels\n",
        "y_test_labels = pd.cut(y_test, bins=[0, 1, 2.9, 4, 5], labels=[\"Bad\", \"Average\", \"Good\", \"Excellent\"])\n",
        "\n",
        "# Convert the predicted ratings to labels\n",
        "y_pred_labels = pd.cut(y_pred, bins=[0, 1, 2.9, 4, 5], labels=[\"Bad\", \"Average\", \"Good\", \"Excellent\"])\n",
        "\n",
        "# Calculate the prediction accuracy\n",
        "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
        "\n",
        "# Plot the predicted vs actual ratings\n",
        "labels = [\"Bad\", \"Average\", \"Good\", \"Excellent\"]\n",
        "test_counts = [sum(y_test_labels == label) for label in labels]\n",
        "pred_counts = [sum(y_pred_labels == label) for label in labels]\n",
        "bar_width = 0.4\n",
        "x1 = [i - bar_width/2 for i in range(len(labels))]\n",
        "x2 = [i + bar_width/2 for i in range(len(labels))]\n",
        "plt.bar(x1, test_counts, width=bar_width, label=\"Actual\")\n",
        "plt.bar(x2, pred_counts, width=bar_width, label=\"Predicted\")\n",
        "plt.xticks(range(len(labels)), labels)\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print the prediction accuracy\n",
        "print(\"Prediction accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "# Exporting the model\n",
        "from joblib import dump\n",
        "\n",
        "# Save the pipeline as a file\n",
        "dump(pipeline, \"/content/model.joblib\")"
      ],
      "metadata": {
        "id": "7TkRPzuCWWZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sending Request to the Model"
      ],
      "metadata": {
        "id": "JOsW8g11Wd_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import load\n",
        "\n",
        "# Load the pipeline from the file\n",
        "pipeline = load(\"/content/model.joblib\")\n",
        "\n",
        "# sending prediction \n",
        "\n",
        "# Example input text\n",
        "input_text = \"This is a normal phone!\"\n",
        "\n",
        "# Clean the text using the clean_text function\n",
        "cleaned_text = clean_text(input_text)\n",
        "\n",
        "# Make a prediction on the cleaned text\n",
        "prediction = pipeline.predict([cleaned_text])\n",
        "\n",
        "# Convert the predicted rating to a label\n",
        "predicted_label = pd.cut(prediction, bins=[0, 1, 2.9, 4, 5], labels=[\"Bad\", \"Average\", \"Good\", \"Excellent\"])\n",
        "\n",
        "print(\"Input text:\", input_text)\n",
        "print(\"Predicted rating:\", prediction)\n",
        "print(\"Predicted label:\", predicted_label)\n"
      ],
      "metadata": {
        "id": "jiI6B4geWg6g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}